{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c3f1d72-2213-49e4-92eb-3fbf5444b4af",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab0845f5-54e5-4369-9805-ea337a03367a",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "def gaussian_kernel(size=21, sigma=2.5):\n",
    "    \"\"\"Create a 2D Gaussian PSF kernel, normalized to sum=1.\"\"\"\n",
    "    assert size % 2 == 1, \"Kernel size should be odd.\"\n",
    "    ax = np.arange(-(size // 2), size // 2 + 1)\n",
    "    xx, yy = np.meshgrid(ax, ax)\n",
    "    k = np.exp(-(xx**2 + yy**2) / (2 * sigma**2))\n",
    "    k /= np.sum(k) #energy =1, the energy of PSF should equal to the energy of delta function\n",
    "    return k.astype(np.float32)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05186505-953c-4abf-a6a4-03eaeb0bdd94",
   "metadata": {},
   "source": [
    "\n",
    "### Explanation `gaussian_kernel(size=21, sigma=2.5)`\n",
    "\n",
    "This function constructs a **2D Gaussian PSF (blur kernel)** and then **normalizes it so the discrete sum equals 1**.  \n",
    "A standard forward imaging model is:\n",
    "\n",
    "$\n",
    "y = k * x + n\n",
    "$\n",
    "\n",
    "where:\n",
    "- $x$ is the sharp image,\n",
    "- $k$ is the PSF / blur kernel,\n",
    "- $n$ is noise,\n",
    "- $*$ denotes 2D convolution.\n",
    "\n",
    "---\n",
    "\n",
    "\n",
    "### 1) Function header\n",
    "- `size` sets the kernel shape as `size × size`.\n",
    "- `sigma` controls blur width (larger $\\sigma$ → more blur).\n",
    "\n",
    "### 2) Ensure odd size\n",
    "```python\n",
    "assert size % 2 == 1, \"Kernel size should be odd.\"\n",
    "````\n",
    "\n",
    "This forces `size` to be odd so the kernel has a well-defined center pixel.\n",
    "\n",
    "### 3) Build coordinate grid\n",
    "\n",
    "```python\n",
    "ax = np.arange(-(size // 2), size // 2 + 1)\n",
    "xx, yy = np.meshgrid(ax, ax)\n",
    "```\n",
    "\n",
    "This creates coordinates:\n",
    "$$\n",
    "a = {-\\lfloor \\tfrac{size}{2}\\rfloor, \\ldots, 0, \\ldots, \\lfloor \\tfrac{size}{2}\\rfloor}\n",
    "$$\n",
    "\n",
    "and then 2D grids $$x_{ij}, y_{ij}$$ (stored in `xx, yy`).\n",
    "\n",
    "### 4) Compute the (unnormalized) 2D Gaussian\n",
    "\n",
    "```python\n",
    "k = np.exp(-(xx**2 + yy**2) / (2 * sigma**2))\n",
    "```\n",
    "\n",
    "This implements:\n",
    "$$\n",
    "k[i,j] = \\exp\\left(-\\frac{x_{ij}^2 + y_{ij}^2}{2\\sigma^2}\\right)\n",
    "$$\n",
    "\n",
    "Note: The continuous Gaussian often includes a prefactor $$\\frac{1}{2\\pi\\sigma^2}$$, but we omit it here because we will normalize discretely.\n",
    "\n",
    "### 5) Normalize to unit-sum\n",
    "\n",
    "```python\n",
    "k /= np.sum(k)\n",
    "```\n",
    "\n",
    "After this step:\n",
    "$$\n",
    "\\sum_{i,j} k[i,j] = 1\n",
    "$$\n",
    "\n",
    "#### Why normalize by the sum?\n",
    "\n",
    "Because this ensures **brightness preservation** under convolution.\n",
    "If the input is a constant image $$x[i,j] = c$$, then:\n",
    "\n",
    "$$\n",
    "(k * x)[i,j] = \\sum_{u,v} k[u,v] , x[i-u, j-v]\n",
    "= \\sum_{u,v} k[u,v] , c\n",
    "= c \\sum_{u,v} k[u,v]\n",
    "= c\n",
    "$$\n",
    "\n",
    "So the blur does **not** change the overall intensity level.\n",
    "\n",
    "#### Important clarification about the comment “energy = 1”\n",
    "\n",
    "* The condition $$\\sum k = 1$$ is **unit-sum / unit DC gain**, not “energy”.\n",
    "* In many signal-processing contexts, “energy” refers to the L2 energy:\n",
    "\n",
    "$$\n",
    "|k|_2^2 = \\sum_{i,j} k[i,j]^2\n",
    "$$\n",
    "\n",
    "For PSFs in imaging, **unit-sum** is typically what we want because it corresponds to conserving total intensity (the PSF behaves like a discrete probability distribution).\n",
    "\n",
    "### 6) Return as float32\n",
    "\n",
    "```python\n",
    "return k.astype(np.float32)\n",
    "```\n",
    "\n",
    "This returns the kernel in `float32` for speed and memory efficiency.\n",
    "\n",
    "---\n",
    "\n",
    "## Summary\n",
    "\n",
    "The function creates:\n",
    "$$\n",
    "k[i,j] \\propto \\exp\\left(-\\frac{i^2 + j^2}{2\\sigma^2}\\right)\n",
    "$$\n",
    "\n",
    "then normalizes it so that:\n",
    "$$\n",
    "\\sum_{i,j} k[i,j] = 1\n",
    "$$\n",
    "\n",
    "which makes convolution preserve constant brightness.\n",
    "\n",
    "---\n",
    "\n",
    "## Optional: If you truly wanted \"unit energy\" instead of \"unit sum\"\n",
    "\n",
    "If you wanted $$|k|_2 = 1$$, you would do:\n",
    "\n",
    "$$\n",
    "k \\leftarrow \\frac{k}{\\sqrt{\\sum_{i,j} k[i,j]^2}}\n",
    "$$\n",
    "\n",
    "But for blur PSFs, **unit-sum normalization** is the standard choice.\n",
    "\n",
    "```\n",
    "```\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87af23e5-6908-4af2-8a14-1ce925546292",
   "metadata": {},
   "outputs": [],
   "source": [
    "def psf2otf(psf, shape):\n",
    "    \"\"\"\n",
    "    Convert a spatial PSF to OTF (FFT of padded+shifted PSF), so that:\n",
    "    circular_conv(x, psf) == ifft2( fft2(x) * OTF )\n",
    "    \"\"\"\n",
    "    #in order to apply frequency filtering, the size of PSF spectrum and the size of image spectrm should be the same\n",
    "    psf_pad = np.zeros(shape, dtype=np.float32)\n",
    "    kh, kw = psf.shape\n",
    "    psf_pad[:kh, :kw] = psf\n",
    "\n",
    "    # Shift PSF center to (0,0) for correct circular convolution in FFT domain\n",
    "    psf_pad = np.roll(psf_pad, -kh // 2, axis=0)\n",
    "    psf_pad = np.roll(psf_pad, -kw // 2, axis=1)\n",
    "\n",
    "    return np.fft.fft2(psf_pad)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17b8936b-4e35-4460-b8e6-1149e5ac1307",
   "metadata": {},
   "source": [
    "### Explanation  `psf2otf(psf, shape)`\n",
    "\n",
    "This function converts a **spatial-domain PSF** (a small blur kernel) into its **frequency-domain representation**, called the **OTF** (Optical Transfer Function).  \n",
    "The key identity it enables is:\n",
    "\n",
    "$$\n",
    "x \\circledast k \\;=\\; \\mathcal{F}^{-1}\\Big( \\mathcal{F}(x)\\,\\odot\\,\\mathcal{F}(k)\\Big)\n",
    "$$\n",
    "\n",
    "where:\n",
    "- $\\circledast$ = **circular convolution** (periodic boundary condition),\n",
    "- $\\mathcal{F}(\\cdot)$ / $\\mathcal{F}^{-1}(\\cdot)$ = 2D FFT / inverse FFT,\n",
    "- $\\odot$ = elementwise multiplication.\n",
    "\n",
    "So once we compute $K=\\mathrm{OTF}=\\mathcal{F}(k)$, we can do fast convolution by multiplying in the frequency domain.\n",
    "\n",
    "---\n",
    "\n",
    "## Why we need padding to `shape`\n",
    "\n",
    "The FFT-based multiplication requires **same-size arrays**:\n",
    "\n",
    "$$\n",
    "X = \\mathcal{F}(x)\\in\\mathbb{C}^{H\\times W},\\quad\n",
    "K = \\mathcal{F}(k)\\in\\mathbb{C}^{H\\times W}\n",
    "$$\n",
    "\n",
    "If the PSF $k$ is smaller (e.g. $21\\times 21$) but the image is $H\\times W$, we must embed/pad the PSF into an $H\\times W$ array before FFT, otherwise $X\\odot K$ is undefined.\n",
    "\n",
    "---\n",
    "\n",
    "## Line-by-line explanation\n",
    "\n",
    "### 1) Allocate a zero-padded array of the target shape\n",
    "```python\n",
    "psf_pad = np.zeros(shape, dtype=np.float32)\n",
    "kh, kw = psf.shape\n",
    "psf_pad[:kh, :kw] = psf\n",
    "````\n",
    "\n",
    "This creates $k_{\\text{pad}}\\in\\mathbb{R}^{H\\times W}$ such that the PSF values are copied into the **top-left corner**:\n",
    "\n",
    "* Before shifting, the PSF center is **not** at the origin index $(0,0)$ (it is typically near $(\\lfloor kh/2\\rfloor,\\lfloor kw/2\\rfloor)$).\n",
    "\n",
    "### 2) Shift the PSF center to frequency-domain “origin” (0,0)\n",
    "\n",
    "```python\n",
    "psf_pad = np.roll(psf_pad, -kh // 2, axis=0)\n",
    "psf_pad = np.roll(psf_pad, -kw // 2, axis=1)\n",
    "```\n",
    "\n",
    "This step is crucial for making the FFT correspond to **circular convolution with a centered kernel**.\n",
    "\n",
    "#### What `np.roll` does\n",
    "\n",
    "`np.roll(A, s, axis)` circularly shifts array `A` by `s` along the given axis:\n",
    "\n",
    "* pixels that “fall off” one end wrap around to the other end (periodic shift).\n",
    "\n",
    "#### Why shift by `-kh//2` and `-kw//2`?\n",
    "\n",
    "In spatial convolution, we usually think the PSF is centered at its middle index.\n",
    "But the FFT assumes the impulse response is aligned so that the “zero-lag” sample is at index $(0,0)$.\n",
    "\n",
    "So we perform:\n",
    "\n",
    "$$\n",
    "k_{\\text{shift}}[i,j] = k_{\\text{pad}}\\Big((i+\\lfloor kh/2\\rfloor)\\bmod H,; (j+\\lfloor kw/2\\rfloor)\\bmod W\\Big)\n",
    "$$\n",
    "\n",
    "This is conceptually the same as applying `ifftshift` (depending on conventions). After this shift, the FFT produces an OTF that correctly matches the intended circular convolution.\n",
    "\n",
    "**If you do NOT shift**, the convolution result will look spatially “mis-registered” (often appearing split/shifted), because the kernel’s center is effectively interpreted as being at the corner.\n",
    "\n",
    "<div style=\"color:red; font-weight:bold;\">\n",
    "My note: This is closely related to FFT princple. FFT assumes periodic function, which extends the original function. This is the same case for both PSF and original function. The \"origin point\" is set at the upleft corner. But remeber the real function is actually a \"infinite large\" image with multiple copys of the original image.If you donot shift the center of psf to the original point. The final result will also be a shifted version of corrected image. Since we can only observe the \"infinite\" image in a finite size window. Thus we can get a misaligned image.But remeber, that is a shifted version of infinite image.  \n",
    "</div>\n",
    "\n",
    "\n",
    "### 3) Take the 2D FFT to get the OTF\n",
    "\n",
    "```python\n",
    "return np.fft.fft2(psf_pad)\n",
    "```\n",
    "\n",
    "This returns:\n",
    "\n",
    "$$\n",
    "K(u,v) = \\mathcal{F}{k_{\\text{shift}}}(u,v)\n",
    "$$\n",
    "\n",
    "which is the **OTF** used in frequency-domain filtering:\n",
    "$$\n",
    "Y = X \\odot K\n",
    "$$\n",
    "\n",
    "---\n",
    "\n",
    "## Summary\n",
    "\n",
    "* **Pad** PSF to image size so FFT-domain multiplication is possible.\n",
    "* **Roll/shift** so the PSF center is at index $$(0,0)$$, matching FFT’s circular-convolution convention.\n",
    "* **FFT2** produces the OTF, enabling fast circular convolution by:\n",
    "  $$\n",
    "  x \\circledast k = \\mathcal{F}^{-1}\\big(\\mathcal{F}(x)\\odot \\mathcal{F}(k)\\big)\n",
    "  $$\n",
    "\n",
    "```\n",
    "```\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81cbbf4b-6626-4510-8b60-6bf93422a6b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def circular_conv2d(x, psf):\n",
    "    \"\"\"2D circular convolution using FFT.\"\"\"\n",
    "    # typical circular convolution,when you use two same size frequency domains times each other\n",
    "    # this is called cicular convolution.\n",
    "    K = psf2otf(psf, x.shape)\n",
    "    return np.real(np.fft.ifft2(np.fft.fft2(x) * K)).astype(np.float32)\n",
    "def forward_model(x, psf, sigma_noise, seed=0):\n",
    "    \"\"\"\n",
    "    y = k*x + n, n ~ N(0, sigma^2)\n",
    "    x is assumed in [0,1].\n",
    "    \"\"\"\n",
    "    rng = np.random.default_rng(seed)\n",
    "    y_blur = circular_conv2d(x, psf)\n",
    "    n = rng.normal(0.0, sigma_noise, size=x.shape).astype(np.float32)\n",
    "    y = y_blur + n\n",
    "    return y, y_blur"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "221b10d2-87e5-4cd4-8acc-5fcd3ec8d2d0",
   "metadata": {},
   "source": [
    "\n",
    "### Explanation `circular_conv2d` and `forward_model`\n",
    "\n",
    "These two functions implement a common **imaging forward model**:\n",
    "\n",
    "$$\n",
    "y = k \\circledast x + n,\\quad n \\sim \\mathcal{N}(0,\\sigma^2)\n",
    "$$\n",
    "\n",
    "where:\n",
    "- $x \\in [0,1]$ is the clean image,\n",
    "- $k$ (your `psf`) is the blur kernel / PSF,\n",
    "- $\\circledast$ denotes **2D circular convolution** (periodic boundary condition),\n",
    "- $n$ is additive white Gaussian noise (AWGN),\n",
    "- $y$ is the observed (blurred + noisy) measurement.\n",
    "\n",
    "---\n",
    "\n",
    "## 1) `circular_conv2d(x, psf)`\n",
    "\n",
    "```python\n",
    "def circular_conv2d(x, psf):\n",
    "    \"\"\"2D circular convolution using FFT.\"\"\"\n",
    "    K = psf2otf(psf, x.shape)\n",
    "    return np.real(np.fft.ifft2(np.fft.fft2(x) * K)).astype(np.float32)\n",
    "````\n",
    "\n",
    "### What it computes\n",
    "\n",
    "This function computes:\n",
    "\n",
    "$$\n",
    "y = x \\circledast k\n",
    "$$\n",
    "\n",
    "Using the convolution theorem (for **circular** convolution):\n",
    "\n",
    "$$\n",
    "\\mathcal{F}(x \\circledast k) ;=; \\mathcal{F}(x)\\odot \\mathcal{F}(k)\n",
    "$$\n",
    "\n",
    "So the algorithm is:\n",
    "\n",
    "1. Compute the OTF (FFT of the padded+shifted PSF):\n",
    "   $$\n",
    "   K = \\mathcal{F}(k_{\\text{shift}})\n",
    "   $$\n",
    "2. Compute FFT of the image:\n",
    "   $$\n",
    "   X = \\mathcal{F}(x)\n",
    "   $$\n",
    "3. Multiply in frequency domain:\n",
    "   $$\n",
    "   Y = X \\odot K\n",
    "   $$\n",
    "4. Inverse FFT to get back to spatial domain:\n",
    "   $$\n",
    "   y = \\mathcal{F}^{-1}(Y)\n",
    "   $$\n",
    "\n",
    "### Why is this called “circular convolution”?\n",
    "\n",
    "Because FFT-based multiplication corresponds to **convolution on a periodic domain**:\n",
    "\n",
    "* The image is assumed to wrap around at the borders.\n",
    "* Mathematically, indices are interpreted modulo the image size $$H,W$$.\n",
    "\n",
    "A precise discrete definition is:\n",
    "\n",
    "$$\n",
    "(x \\circledast k)[i,j] = \\sum_{u=0}^{H-1}\\sum_{v=0}^{W-1} x[u,v]; k[(i-u)\\bmod H,; (j-v)\\bmod W]\n",
    "$$\n",
    "\n",
    "This is different from **linear convolution**, which would require padding the image (e.g., zero-padding) to avoid wrap-around artifacts.\n",
    "\n",
    "### Why `np.real(...)`?\n",
    "\n",
    "Due to floating point round-off, `ifft2` may return tiny imaginary parts (e.g., $$10^{-12}i$$) even when the true result is real.\n",
    "So we take:\n",
    "\n",
    "$$\n",
    "\\Re{y}\n",
    "$$\n",
    "\n",
    "### Why `.astype(np.float32)`?\n",
    "\n",
    "For memory/speed consistency and to match typical imaging pipelines.\n",
    "\n",
    "---\n",
    "\n",
    "## 2) `forward_model(x, psf, sigma_noise, seed=0)`\n",
    "\n",
    "```python\n",
    "def forward_model(x, psf, sigma_noise, seed=0):\n",
    "    \"\"\"\n",
    "    y = k*x + n, n ~ N(0, sigma^2)\n",
    "    x is assumed in [0,1].\n",
    "    \"\"\"\n",
    "    rng = np.random.default_rng(seed)\n",
    "    y_blur = circular_conv2d(x, psf)\n",
    "    n = rng.normal(0.0, sigma_noise, size=x.shape).astype(np.float32)\n",
    "    y = y_blur + n\n",
    "    return y, y_blur\n",
    "```\n",
    "\n",
    "### What it computes\n",
    "\n",
    "It implements:\n",
    "\n",
    "1. **Blur (circular convolution)**:\n",
    "   $$\n",
    "   y_{\\text{blur}} = k \\circledast x\n",
    "   $$\n",
    "2. **Additive Gaussian noise** (i.i.d. per pixel):\n",
    "   $$\n",
    "   n[i,j] \\sim \\mathcal{N}(0,\\sigma^2)\n",
    "   $$\n",
    "3. **Observed measurement**:\n",
    "   $$\n",
    "   y = y_{\\text{blur}} + n\n",
    "   $$\n",
    "\n",
    "### The role of `seed`\n",
    "\n",
    "```python\n",
    "rng = np.random.default_rng(seed)\n",
    "```\n",
    "\n",
    "This makes the noise **reproducible**: with the same `seed`, you get the same random noise realization.\n",
    "\n",
    "### Why return both `(y, y_blur)`?\n",
    "\n",
    "* `y` is what you would “measure” in a realistic imaging scenario.\n",
    "* `y_blur` is useful for debugging/analysis (separating blur-only effects from noise effects).\n",
    "\n",
    "---\n",
    "\n",
    "## Summary\n",
    "\n",
    "* `circular_conv2d`: computes circular convolution efficiently via FFT:\n",
    "\n",
    "$$\n",
    "x \\circledast k = \\mathcal{F}^{-1}\\big(\\mathcal{F}(x)\\odot \\mathcal{F}(k)\\big)\n",
    "$$\n",
    "\n",
    "* `forward_model`: adds Gaussian noise to simulate measurement:\n",
    "\n",
    "$$\n",
    "y = k \\circledast x + n,\\quad n\\sim\\mathcal{N}(0,\\sigma^2)\n",
    "$$\n",
    "\n",
    "```\n",
    "```\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "928e7a48-3ac6-4f46-b6b4-d181fcc6361b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tikhonov_deconv(y, psf, lam):\n",
    "    \"\"\"\n",
    "    argmin_x 0.5||k*x - y||^2 + 0.5*lam||x||^2\n",
    "    Closed-form in Fourier domain:\n",
    "    X = conj(K)*Y / (|K|^2 + lam)\n",
    "    \"\"\"\n",
    "    K = psf2otf(psf, y.shape)\n",
    "    Y = np.fft.fft2(y)\n",
    "    X = np.conj(K) * Y / (np.abs(K) ** 2 + lam)\n",
    "    x_hat = np.real(np.fft.ifft2(X)).astype(np.float32)\n",
    "    return np.clip(x_hat, 0.0, 1.0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba7f3db1-8aa1-4683-9b34-219f35c1eac1",
   "metadata": {},
   "source": [
    "## Explanation `tikhonov_deconv(y, psf, lam)`\n",
    "\n",
    "This function performs **Tikhonov-regularized deconvolution** (also called **ridge-regularized least squares**) under a **circular convolution** model.\n",
    "\n",
    "You assume the observation model is approximately:\n",
    "- blur: $y \\approx k \\circledast x$\n",
    "- (optionally with noise)\n",
    "\n",
    "and you reconstruct $x$ by solving:\n",
    "\n",
    "$$\n",
    "\\hat{x}=\\arg\\min_x \\frac{1}{2}\\|k\\circledast x - y\\|_2^2 \\;+\\; \\frac{\\lambda}{2}\\|x\\|_2^2.\n",
    "$$\n",
    "\n",
    "- The first term enforces data fidelity (match the blurred image).\n",
    "- The second term penalizes large energy in $x$ and stabilizes inversion.\n",
    "- $\\lambda>0$ controls the trade-off: larger $\\lambda$ → smoother / less noisy but more biased.\n",
    "\n",
    "---\n",
    "\n",
    "## Key idea: diagonalization by FFT (circular convolution)\n",
    "\n",
    "For circular convolution, the convolution operator becomes multiplication in the Fourier domain:\n",
    "\n",
    "- Let $K=\\mathcal{F}(k)$ be the OTF, $X=\\mathcal{F}(x)$, $Y=\\mathcal{F}(y)$.\n",
    "- Then $k\\circledast x \\leftrightarrow K\\odot X$.\n",
    "\n",
    "So the optimization decouples frequency-by-frequency:\n",
    "\n",
    "$$\n",
    "\\hat{X}(u,v) = \\arg\\min_{X(u,v)} \\frac{1}{2}|K(u,v)X(u,v)-Y(u,v)|^2 + \\frac{\\lambda}{2}|X(u,v)|^2.\n",
    "$$\n",
    "\n",
    "This is a scalar complex ridge regression. Setting derivative to zero gives the closed form:\n",
    "\n",
    "$$\n",
    "\\hat{X}(u,v)=\\frac{K(u,v)^{*}\\,Y(u,v)}{|K(u,v)|^2+\\lambda}.\n",
    "$$\n",
    "\n",
    "That is exactly the formula in the docstring.\n",
    "\n",
    "\n",
    "\n",
    "---\n",
    "\n",
    "### 1) Derivation in matrix form (ridge regression / Tikhonov)\n",
    "\n",
    "Write the circular convolution as a **linear operator**:\n",
    "\n",
    "- Let $x,y\\in\\mathbb{R}^N$ be vectorized images.\n",
    "- Let $A\\in\\mathbb{R}^{N\\times N}$ be the (block-)circulant matrix representing circular convolution by $k$.\n",
    "  Then $Ax = k\\circledast x$.\n",
    "\n",
    "The objective is:\n",
    "\n",
    "$$\n",
    "J(x)=\\frac{1}{2}\\|Ax-y\\|_2^2+\\frac{\\lambda}{2}\\|x\\|_2^2.\n",
    "$$\n",
    "\n",
    "Compute the gradient (using standard least-squares derivatives):\n",
    "\n",
    "- For $\\frac{1}{2}\\|Ax-y\\|_2^2$, the gradient is $A^\\top(Ax-y)$.\n",
    "- For $\\frac{\\lambda}{2}\\|x\\|_2^2$, the gradient is $\\lambda x$.\n",
    "\n",
    "So:\n",
    "\n",
    "$$\n",
    "\\nabla J(x)=A^\\top(Ax-y)+\\lambda x.\n",
    "$$\n",
    "\n",
    "At the minimizer $\\hat{x}$, set $\\nabla J(\\hat{x})=0$:\n",
    "\n",
    "$$\n",
    "A^\\top(A\\hat{x}-y)+\\lambda\\hat{x}=0\n",
    "\\quad\\Rightarrow\\quad\n",
    "(A^\\top A+\\lambda I)\\hat{x}=A^\\top y.\n",
    "$$\n",
    "\n",
    "Assuming $\\lambda>0$, the matrix $(A^\\top A+\\lambda I)$ is positive definite, so the solution is unique:\n",
    "\n",
    "$$\n",
    "\\hat{x}=(A^\\top A+\\lambda I)^{-1}A^\\top y.\n",
    "$$\n",
    "\n",
    "This is exactly **ridge regression** (same algebra, different application domain).\n",
    "\n",
    "---\n",
    "\n",
    "### 2) Why the Fourier-domain formula appears (diagonalization of circular convolution)\n",
    "\n",
    "For **circular** convolution, $A$ is (block-)circulant, and circulant matrices are diagonalized by the DFT:\n",
    "\n",
    "$$\n",
    "A = F^{-1}\\,\\mathrm{diag}(K)\\,F,\n",
    "$$\n",
    "\n",
    "where:\n",
    "- $F$ is the (2D) DFT operator (implemented by `fft2`),\n",
    "- $\\mathrm{diag}(K)$ is a diagonal operator whose diagonal entries are the OTF values $K(u,v)$,\n",
    "- $K=\\mathcal{F}(k)$.\n",
    "\n",
    "Also, the adjoint corresponds to conjugation in the Fourier domain:\n",
    "\n",
    "$$\n",
    "A^\\top \\;\\text{(or }A^H\\text{ in complex form)}\\;=\\;F^{-1}\\,\\mathrm{diag}(K^*)\\,F.\n",
    "$$\n",
    "\n",
    "Now plug these into the normal equation:\n",
    "\n",
    "$$\n",
    "(A^H A+\\lambda I)\\hat{x}=A^H y.\n",
    "$$\n",
    "\n",
    "Left side:\n",
    "\n",
    "$$\n",
    "A^H A\n",
    "= \\left(F^{-1}\\mathrm{diag}(K^*)F\\right)\\left(F^{-1}\\mathrm{diag}(K)F\\right)\n",
    "= F^{-1}\\mathrm{diag}(|K|^2)F.\n",
    "$$\n",
    "\n",
    "So:\n",
    "\n",
    "$$\n",
    "(A^H A+\\lambda I)\n",
    "= F^{-1}\\mathrm{diag}(|K|^2+\\lambda)\\,F.\n",
    "$$\n",
    "\n",
    "Right side:\n",
    "\n",
    "$$\n",
    "A^H y = F^{-1}\\mathrm{diag}(K^*)\\,F y.\n",
    "$$\n",
    "\n",
    "Let $Y=Fy$ and $\\hat{X}=F\\hat{x}$. Multiply both sides by $F$ (using $FF^{-1}=I$):\n",
    "\n",
    "$$\n",
    "\\mathrm{diag}(|K|^2+\\lambda)\\,\\hat{X}=\\mathrm{diag}(K^*)\\,Y.\n",
    "$$\n",
    "\n",
    "This decouples into independent scalar equations for each frequency bin $(u,v)$:\n",
    "\n",
    "$$\n",
    "(|K(u,v)|^2+\\lambda)\\,\\hat{X}(u,v)=K(u,v)^*\\,Y(u,v).\n",
    "$$\n",
    "\n",
    "Thus:\n",
    "\n",
    "$$\n",
    "\\hat{X}(u,v)=\\frac{K(u,v)^*\\,Y(u,v)}{|K(u,v)|^2+\\lambda}.\n",
    "$$\n",
    "\n",
    "That is the “ridge/Tikhonov” closed-form used in your code.\n",
    "\n",
    "---\n",
    "\n",
    "### 3) Why moving from spatial domain to Fourier domain is *valid* (not a trick)\n",
    "\n",
    "It is valid because the FFT is (up to normalization) a **unitary change of basis**. Conceptually:\n",
    "\n",
    "- You are not changing the problem, only rewriting it in a basis where circular convolution becomes diagonal.\n",
    "- Norms are preserved under a unitary transform (Parseval’s theorem):\n",
    "\n",
    "$$\n",
    "\\|x\\|_2^2 \\propto \\|\\mathcal{F}(x)\\|_2^2,\\qquad\n",
    "\\|Ax-y\\|_2^2 \\propto \\|\\mathcal{F}(Ax-y)\\|_2^2.\n",
    "$$\n",
    "\n",
    "So minimizing the objective in spatial domain is equivalent to minimizing it in Fourier domain, and the Fourier domain is easier because it becomes “one scalar problem per frequency”.\n",
    "\n",
    "**Important condition:** this exact diagonalization requires **circular convolution** (periodic boundary).  \n",
    "If your true physics is **linear convolution with zero boundary**, FFT still can be used, but you must pad appropriately or accept wrap-around artifacts; otherwise the Fourier-domain closed form is solving a *slightly different* boundary-condition model.\n",
    "\n",
    "\n",
    "\n",
    "---\n",
    "\n",
    "## Line-by-line explanation\n",
    "\n",
    "### 1) Convert PSF to OTF with matching size\n",
    "```python\n",
    "K = psf2otf(psf, y.shape)\n",
    "````\n",
    "\n",
    "`psf2otf` pads and shifts the PSF to size `y.shape`, then FFTs it to get $K=\\mathcal{F}(k)$.\n",
    "\n",
    "### 2) FFT of the observed image\n",
    "\n",
    "```python\n",
    "Y = np.fft.fft2(y)\n",
    "```\n",
    "\n",
    "This computes $Y=\\mathcal{F}(y)$.\n",
    "\n",
    "### 3) Closed-form Tikhonov solution (frequency-wise)\n",
    "\n",
    "```python\n",
    "X = np.conj(K) * Y / (np.abs(K) ** 2 + lam)\n",
    "```\n",
    "\n",
    "This implements the elementwise formula:\n",
    "\n",
    "* `np.conj(K)` is $K^*$ (complex conjugate).\n",
    "* `np.abs(K)**2` is $|K|^2$.\n",
    "* Division is elementwise, so each frequency bin is filtered by:\n",
    "\n",
    "$$\n",
    "H(u,v)=\\frac{K(u,v)^*}{|K(u,v)|^2+\\lambda}.\n",
    "$$\n",
    "\n",
    "This filter is sometimes called a **Wiener-like** (but not identical to Wiener) inverse filter: it avoids division by very small $|K|$ values by adding $\\lambda$.\n",
    "\n",
    "### 4) Inverse FFT back to spatial domain\n",
    "\n",
    "```python\n",
    "x_hat = np.real(np.fft.ifft2(X)).astype(np.float32)\n",
    "```\n",
    "\n",
    "Compute $\\hat{x}=\\Re{\\mathcal{F}^{-1}(\\hat{X})}$ and drop tiny imaginary numerical errors.\n",
    "\n",
    "### 5) Clip to a valid intensity range\n",
    "\n",
    "```python\n",
    "return np.clip(x_hat, 0.0, 1.0)\n",
    "```\n",
    "\n",
    "Because you assume the true image $x\\in[0,1]$, clipping keeps the reconstruction in the same range (useful especially when noise/overshoot produces negatives or values > 1).\n",
    "\n",
    "---\n",
    "\n",
    "## Intuition for $\\lambda$\n",
    "\n",
    "* If $\\lambda \\to 0$, the solution approaches the naive inverse filter: $\\hat{X}\\approx Y/K$ (unstable when $K$ has small magnitudes).\n",
    "* If $\\lambda$ is large, high-frequency components (where $|K|$ is small) are strongly suppressed, reducing noise amplification but also losing detail.\n",
    "\n",
    "A simple way to see the stabilization is that the denominator $|K|^2+\\lambda$ is never too close to zero.\n",
    "\n",
    "```\n",
    "```\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33fb391e-ae18-493f-8bc5-2658dcfa4e9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def gd_deconv(y, psf, lam, x_true=None, max_iters=200, patience=20):\n",
    "    \"\"\"\n",
    "    Gradient descent on:\n",
    "      f(x)=0.5||k*x - y||^2 + 0.5*lam||x||^2\n",
    "\n",
    "    With circular convolution:\n",
    "      grad = k^T*(k*x - y) + lam*x\n",
    "    where k^T corresponds to conj(K) in Fourier domain.\n",
    "\n",
    "    Step size alpha chosen via Lipschitz bound:\n",
    "      L = max(|K|^2) + lam, alpha = 1/L\n",
    "\n",
    "    Early stopping (optional):\n",
    "      if x_true provided, stop when PSNR doesn't improve for 'patience' iters.\n",
    "    \"\"\"\n",
    "    K = psf2otf(psf, y.shape)\n",
    "    Y = np.fft.fft2(y)\n",
    "\n",
    "    L = float(np.max(np.abs(K) ** 2).real + lam)\n",
    "    alpha = 1.0 / L\n",
    "\n",
    "    x = y.copy().astype(np.float32)  # init\n",
    "    best_psnr = -np.inf\n",
    "    best_x = x.copy()\n",
    "    bad_count = 0\n",
    "\n",
    "    psnr_trace = []\n",
    "\n",
    "    for it in range(max_iters):\n",
    "        X = np.fft.fft2(x)\n",
    "        resid_f = K * X - Y                        # FFT(k*x - y)\n",
    "        grad_data = np.real(np.fft.ifft2(np.conj(K) * resid_f))  # k^T*(k*x - y)\n",
    "        grad = grad_data + lam * x\n",
    "\n",
    "        x = x - alpha * grad\n",
    "        x = np.clip(x, 0.0, 1.0)\n",
    "\n",
    "        if x_true is not None:\n",
    "            p = peak_signal_noise_ratio(x_true, x, data_range=1.0)\n",
    "            psnr_trace.append(p)\n",
    "            if p > best_psnr + 1e-6:\n",
    "                best_psnr = p\n",
    "                best_x = x.copy()\n",
    "                bad_count = 0\n",
    "            else:\n",
    "                bad_count += 1\n",
    "            if bad_count >= patience:\n",
    "                break\n",
    "\n",
    "    return best_x if x_true is not None else x, alpha, np.array(psnr_trace, dtype=np.float32)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cedff902-20be-405c-8cd0-dfe8eea6cd55",
   "metadata": {},
   "source": [
    "\n",
    "## Explanation: `gd_deconv(y, psf, lam, ...)`\n",
    "\n",
    "This function solves a **Tikhonov-regularized deconvolution** problem using **gradient descent** (instead of the closed-form Fourier solution).\n",
    "\n",
    "It minimizes the objective:\n",
    "\n",
    "$$\n",
    "f(x)=\\frac{1}{2}\\|k\\circledast x - y\\|_2^2+\\frac{\\lambda}{2}\\|x\\|_2^2,\n",
    "$$\n",
    "\n",
    "where:\n",
    "- $y$ is the observed blurred/noisy image,\n",
    "- $k$ is the PSF (blur kernel),\n",
    "- $\\circledast$ is **circular convolution**,\n",
    "- $\\lambda>0$ is the Tikhonov (ridge) regularization weight.\n",
    "\n",
    "---\n",
    "\n",
    "## 1) Gradient formula (why `conj(K)` appears)\n",
    "\n",
    "Define the linear operator $A$ as circular convolution by $k$: $Ax = k\\circledast x$.\n",
    "Then:\n",
    "\n",
    "- data term: $\\frac{1}{2}\\|Ax-y\\|_2^2$ has gradient $A^T(Ax-y)$ (or $A^H(Ax-y)$ in complex notation),\n",
    "- regularizer: $\\frac{\\lambda}{2}\\|x\\|_2^2$ has gradient $\\lambda x$.\n",
    "\n",
    "So the full gradient is:\n",
    "\n",
    "$$\n",
    "\\nabla f(x)=A^T(Ax-y)+\\lambda x.\n",
    "$$\n",
    "\n",
    "For circular convolution, $A$ is diagonalized by FFT:\n",
    "- $Ax \\leftrightarrow K\\odot X$,\n",
    "- $A^T(\\cdot)$ corresponds to multiplication by $K^*$ (complex conjugate) in the Fourier domain.\n",
    "\n",
    "That is why the code uses `np.conj(K)`.\n",
    "\n",
    "---\n",
    "\n",
    "## 2) What each block of code is doing\n",
    "\n",
    "### (a) Precompute OTF and FFT of the observation\n",
    "```python\n",
    "K = psf2otf(psf, y.shape)\n",
    "Y = np.fft.fft2(y)\n",
    "````\n",
    "\n",
    "Here $K=\\mathcal{F}(k)$ and $Y=\\mathcal{F}(y)$.\n",
    "\n",
    "### (b) Step size from a Lipschitz bound\n",
    "\n",
    "```python\n",
    "L = float(np.max(np.abs(K) ** 2).real + lam)\n",
    "alpha = 1.0 / L\n",
    "```\n",
    "\n",
    "For gradient descent on a function with $L$-Lipschitz gradient, a safe constant step size is $\\alpha \\le 1/L$.\n",
    "\n",
    "In this quadratic problem, the Hessian is $A^T A + \\lambda I$.\n",
    "Under circular convolution, the eigenvalues of $A^T A$ are exactly $|K(u,v)|^2$, so the largest eigenvalue is:\n",
    "\n",
    "$$\n",
    "\\lambda_{\\max}(A^T A)=\\max_{u,v}|K(u,v)|^2.\n",
    "$$\n",
    "\n",
    "Therefore a valid Lipschitz constant is:\n",
    "\n",
    "$$\n",
    "L=\\max_{u,v}|K(u,v)|^2+\\lambda,\n",
    "$$\n",
    "\n",
    "and the code chooses $\\alpha = 1/L$.\n",
    "\n",
    "### (c) Initialization and early-stopping bookkeeping\n",
    "\n",
    "```python\n",
    "x = y.copy().astype(np.float32)  # init\n",
    "best_psnr = -np.inf\n",
    "best_x = x.copy()\n",
    "bad_count = 0\n",
    "psnr_trace = []\n",
    "```\n",
    "\n",
    "* Initialize $x_0=y$ (reasonable baseline: start from the blurred/noisy image).\n",
    "* If `x_true` is provided, track PSNR for early stopping.\n",
    "\n",
    "### (d) The gradient descent loop\n",
    "\n",
    "```python\n",
    "X = np.fft.fft2(x)\n",
    "resid_f = K * X - Y\n",
    "grad_data = np.real(np.fft.ifft2(np.conj(K) * resid_f))\n",
    "grad = grad_data + lam * x\n",
    "```\n",
    "\n",
    "Interpretation:\n",
    "\n",
    "* Current estimate in Fourier domain: $X=\\mathcal{F}(x)$.\n",
    "* Residual in Fourier domain:\n",
    "\n",
    "  * $K\\odot X$ corresponds to $\\mathcal{F}(k\\circledast x)$,\n",
    "  * so $K\\odot X - Y = \\mathcal{F}(k\\circledast x - y)$.\n",
    "* Apply adjoint convolution (the $A^T$ step):\n",
    "\n",
    "  * multiply by $K^*$ then inverse FFT:\n",
    "\n",
    "The data-term gradient is:\n",
    "\n",
    "$$\n",
    "\\nabla_x\\left(\\frac{1}{2}|k\\circledast x-y|_2^2\\right)=k^T\\circledast (k\\circledast x-y),\n",
    "$$\n",
    "\n",
    "and in frequency domain this becomes:\n",
    "\n",
    "$$\n",
    "\\mathcal{F}\\{\\text{grad\\_data}\\}\n",
    "= K^{*}\\odot\\bigl(K\\odot X - Y\\bigr).\n",
    "$$\n",
    "\n",
    "Then add the regularizer gradient $\\lambda x$.\n",
    "\n",
    "### (e) Update and projection (clipping)\n",
    "\n",
    "```python\n",
    "x = x - alpha * grad\n",
    "x = np.clip(x, 0.0, 1.0)\n",
    "```\n",
    "\n",
    "This is:\n",
    "\n",
    "* gradient descent step: $x_{t+1}=x_t-\\alpha\\nabla f(x_t)$,\n",
    "* then a simple projection to the valid intensity range $[0,1]$.\n",
    "\n",
    "Clipping is **not** part of the original unconstrained Tikhonov problem; it’s a practical constraint reflecting that pixel intensities are assumed to lie in $[0,1]$.\n",
    "\n",
    "### (f) Early stopping with PSNR (optional)\n",
    "\n",
    "```python\n",
    "p = peak_signal_noise_ratio(x_true, x, data_range=1.0)\n",
    "...\n",
    "if bad_count >= patience: break\n",
    "```\n",
    "\n",
    "* PSNR is computed as:\n",
    "  $$\n",
    "  \\mathrm{PSNR}(x_{\\text{true}},x)=10\\log_{10}\\left(\\frac{\\mathrm{MAX}^2}{\\mathrm{MSE}}\\right),\n",
    "  $$\n",
    "  where $\\mathrm{MAX}=1$ because `data_range=1.0`, and $\\mathrm{MSE}=\\frac{1}{N}|x-x_{\\text{true}}|_2^2$.\n",
    "* If PSNR does not improve for `patience` iterations, stop and return the best encountered solution.\n",
    "\n",
    "---\n",
    "\n",
    "## 3) Outputs\n",
    "\n",
    "```python\n",
    "return best_x if x_true is not None else x, alpha, np.array(psnr_trace, dtype=np.float32)\n",
    "```\n",
    "\n",
    "* If `x_true` is given, returns:\n",
    "\n",
    "  * `best_x`: the iterate with highest PSNR,\n",
    "  * `alpha`: the step size used,\n",
    "  * `psnr_trace`: PSNR over iterations.\n",
    "* Otherwise returns:\n",
    "\n",
    "  * the final `x`,\n",
    "  * `alpha`,\n",
    "  * an empty PSNR trace array.\n",
    "\n",
    "---\n",
    "\n",
    "```\n",
    "```\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7c8cb29-1ceb-4889-9146-632173e01cfd",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (inverse)",
   "language": "python",
   "name": "inverse"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
